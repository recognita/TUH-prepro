{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc278289-d525-4f8b-ae41-dfe113ac3747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file aaaaafmq_s002_t001_raw.fif...\n",
      "Isotrak not found\n",
      "    Range : 0 ... 136999 =      0.000 ...   547.996 secs\n",
      "Ready.\n",
      "Channels marked as bad:\n",
      "none\n",
      "['C3', 'C4', 'CZ', 'F3', 'F4', 'F7', 'F8', 'FP1', 'FP2', 'FZ', 'O1', 'O2', 'P3', 'P4', 'PZ', 'T3', 'T4', 'T5', 'T6']\n",
      "No channels updated. Bads are: []\n",
      "None\n",
      "Bad channels based on mean and std: ['C3', 'C4', 'CZ', 'F3', 'F4', 'F7', 'F8', 'FP2', 'FZ', 'O1', 'O2', 'P3', 'P4', 'PZ', 'T3', 'T4', 'T5', 'T6']\n"
     ]
    }
   ],
   "source": [
    "import mne \n",
    "import numpy as np\n",
    "from scipy.signal import detrend\n",
    "#from mne.preprocessing import find_bad_channels_lof\n",
    "from mne.preprocessing import ICA\n",
    "\n",
    "mne.viz.set_browser_backend('qt')\n",
    "\n",
    "flip0 = mne.io.read_raw('aaaaafmq_s002_t001_raw.fif',   preload=False, verbose=None)\n",
    "flip0.plot(block=True)\n",
    "print (flip0.ch_names)\n",
    "print (flip0.load_bad_channels())\n",
    "#bads, _ = find_bad_channels_lof(flip0, return_scores=True)\n",
    "#print(\"Bad channels detected by Maxwell filter:\", bads)\n",
    "#ica = ICA(n_components=20, random_state=97, max_iter=800)\n",
    "#ica.fit(flip0)\n",
    "\n",
    "# Обнаружение артефактов\n",
    "#ica.detect_artifacts(raw)\n",
    "#bads = ica.exclude\n",
    "#print(\"Bad channels detected by ICA:\", bads)\n",
    "#print (flip0.ch_names)\n",
    "\n",
    "data = flip0.get_data()\n",
    "means = np.mean(data, axis=1)\n",
    "stds = np.std(data, axis=1)\n",
    "\n",
    "# Определение порогов для выявления аномальных каналов\n",
    "mean_threshold = np.mean(means) + 3 * np.std(means)\n",
    "std_threshold = np.mean(stds) + 3 * np.std(stds)\n",
    "\n",
    "# Выявление аномальных каналов\n",
    "bad_channels_mean = np.where(np.abs(means) > mean_threshold)[0]\n",
    "bad_channels_std = np.where(stds > std_threshold)[0]\n",
    "\n",
    "bad_channels = set(bad_channels_mean).union(bad_channels_std)\n",
    "bad_channel_names = [flip0.ch_names[idx] for idx in bad_channels]\n",
    "print(\"Bad channels based on mean and std:\", bad_channel_names)\n",
    "\n",
    "#flip1 = mne.io.read_raw(r'..\\GPT_Dataset\\shapka\\aaaaaaac_s005_t000_raw.fif',   preload=False, verbose=None)\n",
    "#flip1.plot(block=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13f91a55-aa8d-40bb-b233-693a273a932f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing EEG TUH Dataset (n_jobs=1): 100%|██████████████████████████████████████████| 6/6 [00:02<00:00,  2.89it/s]\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import logging\n",
    "import os\n",
    "#from joblib import Parallel, delayed\n",
    "from pathlib import Path\n",
    "import mne\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "REQUIRED_CHANNELS = (\n",
    "    'C3', 'C4', 'CZ', 'F3', 'F4', 'F7', 'F8', 'FP1', 'FP2', 'FZ', 'O1', 'O2', 'P3', 'P4', 'PZ', 'T3', 'T4', 'T5', 'T6'\n",
    ")\n",
    "def channels_available(raw, req_channels):\n",
    "    \"\"\"\n",
    "    Selects only datasets which channels match one of the allowed sequences provided in ch_options\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    raw: mne.io.Raw\n",
    "        An instance of Raw corresponding to a single EEG file\n",
    "    req_channels: list\n",
    "        A list of required channels for a file\n",
    "    \"\"\"\n",
    "    # these are the channels of the recoding\n",
    "    setb = set(raw.ch_names)\n",
    "    # these are the channels we are looking for\n",
    "    seta = set(req_channels)\n",
    "    # if recording contains all channels we are looking for, include it\n",
    "    if seta.issubset(setb):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def preprocess_single_raw(file_path, raw, verbose,\n",
    "                          resampling_parameters, lowpass, logger):\n",
    "    if raw is None:\n",
    "        return None\n",
    "\n",
    "    raw = raw.pick(picks=list(REQUIRED_CHANNELS), verbose=verbose)\n",
    "    if resampling_parameters['sfreq'] != raw.info['sfreq']:\n",
    "        if logger is not None:\n",
    "            logger.info(\n",
    "                f'Resampling {file_path} to {resampling_parameters[\"sfreq\"]} Hz as desired '\n",
    "                f'{resampling_parameters[\"sfreq\"]} Hz != {raw.info[\"sfreq\"]} Hz in a file'\n",
    "            )\n",
    "        raw = raw.resample(verbose=verbose, **resampling_parameters)\n",
    "\n",
    "    if lowpass is not None:\n",
    "        raw = raw.filter( **lowpass, verbose=verbose)\n",
    "\n",
    "    #data = raw.get_data(picks=REQUIRED_CHANNELS, units='uV', verbose=verbose)\n",
    "    #data = data.astype(np.float32)\n",
    "\n",
    "    return raw\n",
    "\n",
    "        \n",
    "def tuh_channels_available(raw, ch_mapping):\n",
    "    ref = 'ar' if raw.ch_names[0].endswith('-REF') else 'le'\n",
    "    return channels_available(raw=raw, req_channels=list(ch_mapping[ref].keys()))\n",
    "    \n",
    "def rename_tuh_channels(raw, ch_mapping):\n",
    "    reference = raw.ch_names[0].split('-')[-1].lower()\n",
    "    assert reference in ['le', 'ref'], 'unexpected referencing'\n",
    "    reference = 'le' if reference == 'le' else 'ar'\n",
    "    raw.rename_channels(ch_mapping[reference])\n",
    "    \n",
    "def load_raw(edf_path, verbose):\n",
    "    channel_mappings = {\n",
    "        'ar': {\n",
    "            'EEG C3-REF': 'C3', 'EEG C4-REF': 'C4', 'EEG CZ-REF': 'CZ',\n",
    "            'EEG F3-REF': 'F3', 'EEG F4-REF': 'F4', 'EEG F7-REF': 'F7', 'EEG F8-REF': 'F8', 'EEG FP1-REF': 'FP1',\n",
    "            'EEG FP2-REF': 'FP2', 'EEG FZ-REF': 'FZ', 'EEG O1-REF': 'O1', 'EEG O2-REF': 'O2', 'EEG P3-REF': 'P3',\n",
    "            'EEG P4-REF': 'P4', 'EEG PZ-REF': 'PZ', 'EEG T3-REF': 'T3', 'EEG T4-REF': 'T4', 'EEG T5-REF': 'T5',\n",
    "            'EEG T6-REF': 'T6'\n",
    "        },\n",
    "        'le': {\n",
    "            'EEG C3-LE': 'C3', 'EEG C4-LE': 'C4', 'EEG CZ-LE': 'CZ',\n",
    "            'EEG F3-LE': 'F3', 'EEG F4-LE': 'F4', 'EEG F7-LE': 'F7', 'EEG F8-LE': 'F8', 'EEG FP1-LE': 'FP1',\n",
    "            'EEG FP2-LE': 'FP2', 'EEG FZ-LE': 'FZ', 'EEG O1-LE': 'O1', 'EEG O2-LE': 'O2', 'EEG P3-LE': 'P3',\n",
    "            'EEG P4-LE': 'P4', 'EEG PZ-LE': 'PZ', 'EEG T3-LE': 'T3', 'EEG T4-LE': 'T4', 'EEG T5-LE': 'T5',\n",
    "            'EEG T6-LE': 'T6'\n",
    "        }\n",
    "    }\n",
    "\n",
    "    raw = mne.io.read_raw_edf(edf_path, preload=True, verbose=verbose)\n",
    "\n",
    "    if tuh_channels_available(raw=raw, ch_mapping=channel_mappings):\n",
    "        rename_tuh_channels(raw=raw, ch_mapping=channel_mappings)\n",
    "        return raw\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def get_numpy_tuh_path(edf_path, np_format):\n",
    "    #edf_path = os.path.normpath(edf_path)\n",
    "    path_parts = edf_path.split(os.sep)\n",
    "    path_parts[-1] = path_parts[-1][:-len('.edf')] +'_raw' + np_format\n",
    "    np_path = os.path.join(*path_parts)\n",
    "    return np_path\n",
    "\n",
    "def preprocess_single_tuh_file(edf_path, verbose=False, resampling_parameters=None, lowpass=None, logger=None, np_format='.fif'):\n",
    "    try:\n",
    "        raw = load_raw(edf_path=edf_path, verbose=verbose)\n",
    "        data = preprocess_single_raw(\n",
    "            file_path=edf_path, raw=raw, verbose=verbose, resampling_parameters=resampling_parameters,\n",
    "            lowpass=lowpass, logger=logger\n",
    "        )\n",
    "        if data is not None:\n",
    "            home_path = Path(get_numpy_tuh_path(edf_path=edf_path, np_format=np_format))\n",
    "            home_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "            if np_format == '.fif':\n",
    "                data.save(home_path, overwrite=True)\n",
    "            else:\n",
    "                raise NotImplementedError(\"Only '.fif' format is supported.\")\n",
    "            return 0\n",
    "        else:\n",
    "            logging.info(f'{edf_path} data is None. A file did not fit provided requirements (i.e. too short, '\n",
    "                         f'wrong channels), skipped')\n",
    "            return None\n",
    "    except Exception:\n",
    "        if logger:\n",
    "            logger.exception(f'{edf_path} failed to process')\n",
    "        else:\n",
    "            logging.exception(f'{edf_path} failed to process')\n",
    "        return None\n",
    "    \n",
    "def preprocess_files(df_path, verbose, np_format, \n",
    "                           resampling_parameters, lowpass, n_jobs, logger):\n",
    "    df = pd.read_csv(df_path)\n",
    "    file_paths = df['file_path'].tolist()\n",
    "    if n_jobs == 1:\n",
    "        results = [preprocess_single_tuh_file(\n",
    "            edf_path=edf_path, verbose=verbose,\n",
    "            resampling_parameters=resampling_parameters, lowpass=lowpass,\n",
    "            np_format = np_format\n",
    "        )\n",
    "            for edf_path in tqdm(file_paths, total=len(file_paths),\n",
    "                                 desc=f'Preprocessing EEG TUH Dataset (n_jobs={n_jobs})')]\n",
    "    #else:\n",
    "    #    results = Parallel(n_jobs)(delayed(\n",
    "     #       preprocess_single_tuh_file)(\n",
    "     #        edf_path=edf_path, verbose=verbose,\n",
    "     #       resampling_parameters=resampling_parameters, lowpass=lowpass,\n",
    "      #      saving_format = saving_format\n",
    "      #  ) \n",
    "       #     for edf_path in tqdm(file_paths, total=len(file_paths),\n",
    "        #                       desc=f'Preprocessing EEG TUH Dataset (n_jobs={n_jobs})'))\n",
    "    return results\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    logging.basicConfig(filename='eeg_tuh_preprocessing_logs.log',\n",
    "                        filemode='a',\n",
    "                        format='%(asctime)s,%(msecs)d %(name)s %(levelname)s %(message)s',\n",
    "                        datefmt='%H:%M:%S',\n",
    "                        level=logging.INFO)\n",
    "    logger = logging.getLogger(__name__)\n",
    "    logger.info('Start preprocessing the EEG TUH Dataset')\n",
    "\n",
    "    preprocess_files(\n",
    "        #ds_root= '..',\n",
    "        df_path = 'mozgi.csv',\n",
    "        verbose='WARNING', np_format='.fif',\n",
    "        resampling_parameters={\n",
    "            'sfreq': 250,\n",
    "        },\n",
    "        \n",
    "        lowpass = {\n",
    "            'l_freq': None,\n",
    "            'h_freq': 80,\n",
    "            'method': 'iir',\n",
    "            'iir_params': {\n",
    "                'ftype': 'butter',\n",
    "                'order': 3 \n",
    "            }\n",
    "        },\n",
    "        n_jobs= 1,\n",
    "\n",
    "        logger=logger\n",
    "    )\n",
    "\n",
    "    logger.info('Preprocessing done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b7bf65-86d8-49b9-abf8-19237f8d6f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_root= '..'\n",
    "file_paths = list(glob.glob(os.path.join(ds_root, '**/*.edf'), recursive=True))\n",
    "a= create_data_frame (file_paths)\n",
    "six = preprocess_files (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e6d336-7b1e-4765-bd09-7a7a2718fca7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f256c9-ba08-4c41-83f8-adf58e6d885b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
